{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure, adjusted_rand_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE = 'GloVe'\n",
    "CONCEPTNET = 'Conceptnet'\n",
    "WORD2VEC = 'Word2Vec'\n",
    "FAST_TEXT = 'FastText'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CrossNER_NOUN_PRON.pickle', 'rb') as f:\n",
    "    ner_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters = ['person', 'organization', 'location', 'miscellaneous']\n",
    "\n",
    "politics = ['politician', 'political party', 'election',\n",
    "           # 'country', 'location', 'event', 'miscellaneous', 'organization', 'person'\n",
    "           ]\n",
    "\n",
    "nat_science = ['scientist', 'university',\n",
    "               'discipline', 'enzyme', 'protein',\n",
    "               'chemical compound', 'chemical element',\n",
    "               'astronomical object', 'academic journal', 'theory',\n",
    "              # 'person', 'country', 'event', 'award', 'miscellaneous', 'organization', 'location'\n",
    "              ]\n",
    "\n",
    "music = ['music genre', 'song', 'band', 'album', 'musical artist', 'musical instrument',\n",
    "         #'organization', 'person', 'miscellaneous', 'award', 'event', 'country', 'location',\n",
    "        ]\n",
    "\n",
    "\n",
    "lit = ['book', 'writer', 'poem', 'event', 'magazine',\n",
    "       #'award', 'person', 'location', 'organization', 'country', 'miscellaneous',\n",
    "      ]\n",
    "\n",
    "ai = ['field', 'task', 'product', 'algorithm', 'researcher', 'metrics', 'university',\n",
    "      #'country', 'person', 'organization', 'location', 'miscellaneous'\n",
    "     ]\n",
    "\n",
    "domains = [reuters, politics, nat_science, music, lit, ai]\n",
    "\n",
    "\n",
    "labels = {\n",
    "    'Politics': politics,\n",
    "    'Natural Science': nat_science,\n",
    "    'Music': music,\n",
    "    'Literature': lit,\n",
    "    'AI': ai,\n",
    "}\n",
    "\n",
    "label_nums = {\n",
    "    'Politics': 0,\n",
    "    'Natural Science': 1,\n",
    "    'Music': 2,\n",
    "    'Literature': 3,\n",
    "    'AI': 4\n",
    "}\n",
    "\n",
    "num_domains = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(embedding_file: str):\n",
    "    words_df = pd.read_csv(embedding_file, sep=\" \", index_col=0,\n",
    "                           na_values=None, keep_default_na=False,\n",
    "                           header=None, quoting=csv.QUOTE_NONE)\n",
    "    word_embeddings = {word: words_df.loc[word].values\n",
    "                       for word in words_df.index.values}\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(word_embeddings):\n",
    "    words_arr, X, Y = [], [], []\n",
    "\n",
    "    for label, words in labels.items():\n",
    "        for word in words:\n",
    "            Y.append(label_nums[label])\n",
    "            words_arr.append(word)\n",
    "            clean_word = word.replace(' ', '_')\n",
    "\n",
    "            # Strategy: If full word, i.e. 'political_party' is present, use that.\n",
    "            # Otherwise take average of 'political' and 'party'\n",
    "            if clean_word in word_embeddings:\n",
    "                word_vec = word_embeddings[clean_word]                  \n",
    "            else:\n",
    "                word_vec = np.mean([word_embeddings[subword] for subword in word.split()], axis=0)\n",
    "\n",
    "            X.append(word_vec)\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y, words_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_ner(ner_dict, word_embeddings):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for label_num, domain in enumerate(ner_dict.keys()):\n",
    "        for pos in ner_dict[domain].keys():\n",
    "            for word_info in ner_dict[domain][pos]:\n",
    "                word = word_info[0]\n",
    "                \n",
    "                clean_word = word.replace(' ', '_')\n",
    "\n",
    "                # Strategy: If full word, i.e. 'political_party' is present, use that.\n",
    "                # Otherwise take average of 'political' and 'party'\n",
    "                if clean_word in word_embeddings:\n",
    "                    word_vec = word_embeddings[clean_word]                  \n",
    "                else:\n",
    "                    word_vec = np.mean([word_embeddings[subword] for subword in word.split()], axis=0)\n",
    "                \n",
    "                X.append(word_vec)\n",
    "                Y.append(label_num)\n",
    "\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_word_embeds_labels(embed):\n",
    "    word_embeddings = read_embeddings(f'embeddings-{embed.lower()}.txt')\n",
    "    X, Y, _ = transform_data(word_embeddings)\n",
    "    kmeans = KMeans(n_clusters=num_domains, random_state=0).fit(X)\n",
    "    rand = adjusted_rand_score(Y, kmeans.labels_)\n",
    "    v = homogeneity_completeness_v_measure(Y, kmeans.labels_)\n",
    "    return rand, v[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3470258626566143, 0.610651070676727)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_word_embeds_labels(GLOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5464661034411703, 0.7360997227311346)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_word_embeds_labels(CONCEPTNET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_word_embeds_labels(FAST_TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_word_embeds_concepts(embed):\n",
    "    word_embeddings = read_embeddings(f'embeddings-{embed.lower()}.txt')\n",
    "    X, Y = transform_data_ner(ner_dict, word_embeddings)\n",
    "    kmeans = KMeans(n_clusters=num_domains, random_state=0).fit(X)\n",
    "    rand = adjusted_rand_score(Y, kmeans.labels_)\n",
    "    v = homogeneity_completeness_v_measure(Y, kmeans.labels_)\n",
    "    return rand, v[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68036, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06304297253321657, 0.12301210686240537)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_word_embeds_concepts(GLOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68036, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.030742400849830116, 0.09710381818623326)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_word_embeds_concepts(CONCEPTNET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_word_embeds_concepts(FAST_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 300)\n",
      "(31, 300)\n",
      "(68036, 300)\n",
      "(68036, 300)\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for amount in ['Labels', 'Concepts']:\n",
    "    func = score_word_embeds_labels if amount == 'Labels' else score_word_embeds_concepts\n",
    "    for embed in [GLOVE, CONCEPTNET]:  # Add FastText as well if you have the embeds\n",
    "        rand, v_measure = func(embed)\n",
    "        rows.append([amount, embed, rand, v_measure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Labels', 'GloVe', 0.3470258626566143, 0.610651070676727],\n",
       " ['Labels', 'Conceptnet', 0.5464661034411703, 0.7360997227311346],\n",
       " ['Concepts', 'GloVe', 0.06304297253321657, 0.12301210686240537],\n",
